{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['webpage_url', 'total_images'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_link(link):\n",
    "    try:\n",
    "        link_response = BeautifulSoup(requests.get(link,\n",
    "                                    headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36 Edg/125.0.0.0'}).text)\n",
    "        return link_response\n",
    "    except Exception as e:\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_image(link):\n",
    "    try:\n",
    "        link_response = requests.get(link,\n",
    "                                    headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36 Edg/125.0.0.0'})\n",
    "        return link_response\n",
    "    except Exception as e:\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder(folder_name, parent=''):\n",
    "    try:\n",
    "        if parent == '':\n",
    "            os.makedirs(folder_name)\n",
    "        else:\n",
    "            os.makedirs(f\"{parent}/{folder_name}\")\n",
    "        return 'Folder created successfully'\n",
    "    except Exception as e:\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_img(resp_data, folder_name):\n",
    "    link_data = list(set([link.get('src') for link in resp_data.find_all('img')]))\n",
    "    for img in link_data:\n",
    "        img_name = img.split('/')[-1]\n",
    "        with open(f'{os.getcwd()}/{folder_name}/{img_name}', \"wb\") as file:\n",
    "            file.write(crawl_image(img).content)\n",
    "    return len(link_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(resp_data, folder_name):\n",
    "    text_data = resp_data.text\n",
    "    with open(f\"{folder_name}/{folder_name}.txt\", 'w') as file:\n",
    "        file.write(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_links(resp_data):\n",
    "    link_data = list(set([link.get('href') for link in resp_data.find_all('a')]))    \n",
    "    return link_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_pagination(link):\n",
    "    resp_data = crawl_link(link)\n",
    "    pg_urls = []\n",
    "    global pagi\n",
    "\n",
    "    if pagi == False:\n",
    "        try:\n",
    "            total_pages = resp_data.find('div', {'class': 'wp-pagenavi'}).find('span', {'class': 'pages'}).text.split()[-1]\n",
    "            for pg in range(1, int(total_pages)+1):\n",
    "                pg_urls.extend(extract_links(crawl_link(f'{link}page/{pg}/')))\n",
    "            pagi = True\n",
    "        except Exception as e:\n",
    "            print('No pagination', link)\n",
    "    else:\n",
    "        return []\n",
    "    return pg_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "landing_url = 'https://franchisesuppliernetwork.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "landing_page_response=crawl_link(landing_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = extract_links(crawl_link('https://franchisesuppliernetwork.com/fsn-suppliers'))\n",
    "for nav_link in links:\n",
    "    links.extend(check_pagination(nav_link))\n",
    "    if pagi:\n",
    "        break\n",
    "print(len(links))\n",
    "pos = 0\n",
    "for link in links[:1]:\n",
    "    try:\n",
    "        link_resp = crawl_link(link)\n",
    "        folder = link[:-1].replace('https://franchisesuppliernetwork.com/', '').replace('-', '_').replace('/', '_')\n",
    "        try:\n",
    "            df.at[pos, 'webpage_url'] = link\n",
    "            create_folder(folder)\n",
    "            extract_text(link_resp, folder)\n",
    "            df.at[pos, 'total_images'] =extract_img(link_resp, folder)\n",
    "        except Exception as e:\n",
    "            print(f\"couldn't crawl this link:- {link}\", e)\n",
    "    except Exception as e:\n",
    "        print(e, link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
